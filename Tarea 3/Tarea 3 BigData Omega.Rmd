---
title: "Tarea 3 - Big Data"
author: "Shanthal Chavarría"
date: "`r Sys.Date()`"
output:
  html_document: 
    df_print: paged 
    highlight: kate
    toc: TRUE
    toc_float: TRUE
---


```{r setup, echo=FALSE, cache=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
	             cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```

```{r}
library(tidyverse)
library(glue)
library(scales)
library(traineR)

resumen.lineas <- function(resultados, titulo) {
  datos.grafico <- pivot_longer(
    resultados,
    cols = -rep,
    names_to = 'name',
    values_to = 'value'
  )
  
  ggplot(datos.grafico, aes(y = value, x = rep, color = name)) +
    geom_line(size = 1) +
    geom_point() +
    scale_y_continuous(labels = label_number()) +
    scale_x_continuous(breaks = seq.int(1,max(datos.grafico$rep),1)) +
    theme_minimal(base_size = 16) +
    labs(color = '',
         x = 'repetición',
         title = titulo,
         y = paste('', titulo)) +
    theme(axis.text.y = element_text(vjust = 0),
          legend.position = "top",
          plot.title = element_text(hjust = 0.5))
}



```

## Ejercicio 1: [30 puntos] 
Esta pregunta utiliza los datos (tumores.csv). Se trata de un conjunto de datos de características del tumor cerebral que incluye cinco variables de primer orden y ocho de textura y cuatro parámetros de evaluación de la calidad con el nivel objetivo. La variables son: Media, Varianza, Desviación estándar, Asimetría, Kurtosis, Contraste, Energía, ASM (segundo momento angular), Entropía, Homogeneidad, Disimilitud, Correlación, Grosor, PSNR (Pico de la relación señal-ruido), SSIM (Índice de Similitud Estructurada), MSE (Mean Square Error), DC (Coeficiente de Dados) y la variable a predecir tipo (1 = Tumor, 0 = No-Tumor).

```{r}
library(readr)

datos <- read.table("Datos Tarea/tumores.csv", header = T, sep = ",", dec = ".", stringsAsFactors = T)[,-1]


```

## 1. El objetivo de este ejercicio es calibrar el método de ADA para esta Tabla de Datos. Aquí interesa predecir en la variable tipo. Usando los paquetes `snow` y `traineR` programe en paralelo 5 Validaciones Cruzadas con 10 grupos calibrando el modelo de acuerdo con los tres tipos de algoritmos que permite, `discrete`, `real` y `gentle`. Para medir la calidad de método sume la cantidad de 1’s detectados en los diferentes grupos. Luego grafique las 5 iteraciones para los tres algoritmos en el mismo gráfico. ¿Se puede determinar con claridad cúal algoritmo es el mejor? Para generar los modelos predictivos use las siguientes instrucciones:

`modelo<-train.ada(tipo~.,data=taprendizaje,iter=80,nu=1,type="discrete")`
`modelo<-train.ada(tipo~.,data=taprendizaje,iter=80,nu=1,type="real")`
`modelo<-train.ada(tipo~.,data=taprendizaje,iter=80,nu=1,type="gentle")`

```{r}
library(snow)
library(traineR)
library(caret)

peones <- parallel::detectCores()
clp <- makeCluster(peones, type = "SOCK")

ejecutar.prediccion <- function(datos, formula, muestra, metodo, ...) {
  ttesting <- datos[muestra, ]
  ttraining <- datos[-muestra, ]
  #modelo <- metodo(formula, data = ttraining, ...)
  modelo <- do.call(metodo, list(formula, data = ttraining, ...))
  prediccion <- predict(modelo, ttesting, type = "class")
  
  MC <- confusion.matrix(ttesting, prediccion)
  return(MC)
}

clusterExport(clp, "datos")   

ignore <- clusterEvalQ(clp, {
      library(traineR)
      ejecutar.prediccion <- function(datos, formula, muestra,metodo, ...) {
        ttesting <- datos[muestra, ]
        taprendizaje <- datos[-muestra, ]
        modelo <- metodo(formula, data = taprendizaje, ...)
        prediccion <- predict(modelo, ttesting, type = "class")
        MC <- confusion.matrix(ttesting, prediccion)
        return(MC)
      }
      return(NULL)
})

```

```{r}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

algoritmos <- c("discrete", "real", "gentle")

# Exportamos paquetes a los procesadores
ignore <- clusterEvalQ(clp, {
  library(dplyr)
  library(traineR)
  return(NULL)
})


MCs.discrete <- list()
MCs.real <- list()
MCs.gentle <- list()


for(i in 1:cantidad.validacion.cruzada) {
  grupos <- createFolds(1:numero.filas, cantidad.grupos)
  MC.discrete <- matrix(c(0,0,0,0),nrow=2)
  MC.real <- matrix(c(0,0,0,0),nrow=2)
  MC.gentle <- matrix(c(0,0,0,0),nrow=2)
  
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]
            
    ### Inserta estas 1 variable en cada peón
    clusterExport(clp, "muestra")
    
    resultado <- clusterApply(clp, algoritmos, function(pkernels) {
      MC <- ejecutar.prediccion(datos, tipo ~ .,muestra, train.ada, iter = 20 , nu = 1, type = pkernels)
      valores <- list(Tipo = pkernels, Resultado = MC)
      valores
    })
    
    for (j in 1:length(algoritmos)) {
      if (resultado[[j]][[1]] == "discrete") 
         MC.discrete <- MC.discrete + resultado[[j]][[2]] 
      else if (resultado[[j]][[1]] == "real")
         MC.real <- MC.real + resultado[[j]][[2]] 
      else if (resultado[[j]][[1]] == "gentle")
         MC.gentle <- MC.gentle + resultado[[j]][[2]] 
    }
  }
      
  MCs.discrete[[i]] <- MC.discrete
  MCs.real[[i]] <- MC.real
  MCs.gentle[[i]] <- MC.gentle
}


stopCluster(clp) # No olvidar cerrar el proceso

MCs.real
```

```{r, fig.width=12, fig.height=6}
resultado.si <- data.frame(
  "rep" = 1:cantidad.validacion.cruzada,
  "discrete"     = sapply(MCs.discrete, function(MC) MC[2,2]),
  "real"     = sapply(MCs.real, function(MC) MC[2,2]),
  "gentle" = sapply(MCs.gentle, function(MC) MC[2,2]))

resultado.si


resumen.lineas(resultado.si, "Cantidad de 1s")
```

